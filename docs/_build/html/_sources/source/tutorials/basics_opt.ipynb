{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ecd959",
   "metadata": {},
   "source": [
    "# Getting Started: Network Optimization\n",
    "\n",
    "The optimization code is a wrapper around the analysis code. Given an initial network configuration of sensors, the code will add a desired number of sensors to the network. The goal of the optimization is to maximized the EIG of the new sensor network. This is done with a sequential (greedy) optimization that adds sensors one at a time to the initial network. Each optimization is done using a Bayesian optimization method that construct a Gaussian process (GP) surrogate model of the EIG optimization surface. This is done by evaluating many potential new sensor locations and measuring the EIG using the analysis code. These data are then used to construct the surrogate and inform new trial points to query the EIG function. The code then returns the new sensor network after the optimal sensors have been added.\n",
    "\n",
    "The optimization code is contained within the script `network_opt.py`. \n",
    "This script takes four arguments: a configuration file, an output file name, the path to a folder to save the output and all intermediate files, and a verbosity control. An example configuration file, which we call `opt_inputs.dat`, might look like this:\n",
    "\n",
    "```text  \n",
    "1\n",
    "20\n",
    "sensor_optimization_boundary.json\n",
    "2,2,0\n",
    "0\n",
    "1024\n",
    "4096\n",
    "2\n",
    "event_sampling_boundary.json\n",
    "mpiexec --bind-to core --npernode 16 --n 512\n",
    "unif_prior.py\n",
    "10\n",
    "40.0, -111.5,0.1,2,0  \n",
    "```\n",
    "Here, observe several things about the input file:\n",
    "- Line 3 specifies the filename (and path, if in a different directory) of the shapefile used to define the boundary for the sensors. At this time, a boundary file must always be provided (meaning that if we wanted to simply optimize the sensors over a square domain, we would need to provide a file specifying that). \n",
    "- Line 4 specifies that we wish to use sensors with an SNR offset of 2, an output vector length of 4, and of type `0`--meaning sensors that detect seismic waves. \n",
    "- Line 10 uses nodes with 36 cores per node and specifies 256 total cores. If the server being used had a different architecture, this line would need to be modified to match the server.\n",
    "- Lines 9 specifies the file defining the boundary from which events may be sampled.\n",
    "- Line 11 specifies the file that contains the proper functions for sampling events (see [Customizing the event prior](prior.ipynb) for details).\n",
    "\n",
    "For more information on input files, see [Writing input files](inputs.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a91b2ff",
   "metadata": {},
   "source": [
    "(run-the-code)=\n",
    "## Running the code\n",
    "The code can be run interactively, either locally or on an HPC system, or it can be run through a HPC scheduler. This tutorial assumes the HPC system uses [Slurm](https://slurm.schedmd.com/documentation.html).\n",
    "\n",
    "The code for optimizing a network is contained in the Python file `network_opt.py`, which is executed with the with the following arguments:\n",
    "\n",
    "-   Input file: path to the input file (see [Writing input files](inputs.ipynb) for more details)\n",
    "\n",
    "-   Output file: Path to the location and filename where the\n",
    "    outputs will be saved. File must be in `.npz` format.\n",
    "    \n",
    "-   Output path: Location where a directory will be created to store the output\n",
    "    and temporary files created by the run.\n",
    "\n",
    "-   Verbosity: One of 2 verbosity levels may be specified: `0`, `1`:\n",
    "\n",
    "    -   `0` has no output other than the final optimized network.\n",
    "\n",
    "    -   `1` is the most verbose with printed statements throughout the\n",
    "        code describing what is going on. This verbosity level also\n",
    "        causes each intermediate input files to the `eig_calc.py` script,\n",
    "        the outputs of those intermediate runs,\n",
    "        and the intermediate optimization objects to be stored in the output path directory.s\n",
    "\n",
    "### Running using HPC interactively\n",
    "To submit an interactive job, use the `salloc` command. The command\n",
    "`salloc` requests a slurm allocation, and has several flags that are\n",
    "used to specify the details of the allocation. This varies by system, \n",
    "but typically the number of nodes and the allocation time are required:\n",
    "\n",
    "-   `-nodes`: The number of nodes to request.\n",
    "\n",
    "-   `--time`: The time the nodes will be allocated to your account\n",
    "\n",
    "An example job allocation request looks like this:\n",
    "\n",
    "```shell\n",
    "salloc --nodes=2 --time=2:00:00\n",
    "```\n",
    "\n",
    "This command is requesting 2\n",
    "nodes for a length of 2 hours. For more details on `salloc`, see the\n",
    "Slurm documentation: <https://slurm.schedmd.com/documentation.html>.\n",
    "\n",
    "Once you have an allocation, you can now submit the job. For example:\n",
    "```shell\n",
    "python3 network_opt.py inputs.dat outputs.npz ouput_path 1\n",
    "```\n",
    "which executes the `network_opt.py` script with Python,\n",
    "reads the input data from `inputs.dat`, saves the\n",
    "output data to `outputs.npz`, in a directory called `output_path`, and uses verbose setting `1`.\n",
    "\n",
    "### Running on HPC with script \n",
    "\n",
    "A bash script can be written that will submit a job to the HPC job\n",
    "queue. This does not require the user to specifically allocate nodes to\n",
    "use for the job; nodes will be allocated and the job will begin\n",
    "automatically once the number of nodes specified in the bash script are\n",
    "available.\n",
    "An example script might look like\n",
    "\n",
    "```text\n",
    "#!/bin/bash\n",
    "## Do not put any commands or blank lines before the #SBATCH lines\n",
    "#SBATCH --nodes=16                   # Number of nodes - all cores \n",
    "                                     #per node are allocated to the job\n",
    "#SBATCH --time=04:00:00              # Wall clock time (HH:MM:SS) - \n",
    "                                     # once the job exceeds this time, the job will be terminated (default is 5 minutes)\n",
    "#SBATCH --job-name=net_analysis          # Name of job\n",
    "#SBATCH --export=ALL                 # export environment variables from the submission env\n",
    "                                     # (modules, bashrc etc)\n",
    "\n",
    "nodes=$SLURM_JOB_NUM_NODES           # Number of nodes - the number of \n",
    "                                     # nodes you have requested (for a \n",
    "                                     # list of SLURM environment \n",
    "                                     # variables see \"man sbatch\")\n",
    "cores=16                             # Number MPI processes to run \n",
    "                                     # on each node (a.k.a. PPN)\n",
    "                                   \n",
    "\n",
    "python3 network_opt.py inputs.dat output_path outputs.npz 1\n",
    "```\n",
    "\n",
    "This script can then be submitted\n",
    "using the `sbatch` command:\n",
    "```shell\n",
    "sbatch network_opt_batch_submission_script.bash\n",
    "```\n",
    "For a comprehensive\n",
    "list of available options, see the Slurm documentation\n",
    "(<https://slurm.schedmd.com/documentation.html>), and in particular the\n",
    "Slurm command/option summary, found\n",
    "[here](https://slurm.schedmd.com/documentation.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aba8d9",
   "metadata": {},
   "source": [
    "(code-outputs)=\n",
    "## Optimization output\n",
    "\n",
    "When `network_opt.py` finishes, it will display the optimized sensor\n",
    "network configuration e.g. for each sensor its lat, long, noise level,\n",
    "number of output variables, and sensor type. This network configuration\n",
    "will then be saved in the output numpy file (e.g. `opt_network.npz`).\n",
    "\n",
    "Additionally, if the verbose flag is set to 1, two files are created per\n",
    "optimization level where a new sensor number is being placed. The first\n",
    "file is `result*.pkl`, where `*` is the sensor number being placed. This\n",
    "file contains an optimization result object. This object contains\n",
    "information about the GP surrogate used to find the optimization\n",
    "objective and the data used to fit it. More information can be found in\n",
    "the Scikit-Learn documentation\n",
    "(<https://scikit-optimize.github.io/stable/auto_examples/store-and-load-results.html>).\n",
    "The second file, `result_eigdata*.npz` is a numpy file that contains\n",
    "three variables: `sensors`, `eigdata_full`, and `Xs`. `sensors` lists\n",
    "the current network configuration before optimization. `eigdata_full`\n",
    "contains the \\[EIG, std EIG, minESS\\] for each trial new sensor location\n",
    "to augment the current network. `Xs` includes the trial sensor\n",
    "locations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5036a6e",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "For examples of using this code to optimize a sensor network, see the next section, [Performing bounded optimization](bounded.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
